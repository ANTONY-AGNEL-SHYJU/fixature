{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVDAUMe77/aUbcsk26Pz38",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANTONY-AGNEL-SHYJU/fixature/blob/main/right_and_left_eeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SbLdbzNvT2lB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a029db5b-b957-4c4f-faa0-4e4b9329a343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Starting data processing...\n",
            "Processing file: S001R04.edf\n",
            "Processing file: S001R08.edf\n",
            "Processing file: S001R12.edf\n",
            "\n",
            "✅ Data processing complete!\n",
            "Shape of feature matrix (X): (45, 48)\n",
            "Shape of labels vector (y): (45,)\n",
            "\n",
            "Starting model training...\n",
            "\n",
            "✅ Model training complete!\n",
            "==============================\n",
            "ACCURACY ON TEST DATA: 55.56%\n",
            "==============================\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "# Install the 'mne' library for reading EEG data files\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "import pywt\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE PROCESSING FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def extract_features(signal):\n",
        "    \"\"\"Extracts features from a signal using Discrete Wavelet Transform (DWT).\"\"\"\n",
        "    coeffs = pywt.wavedec(signal, 'db4', level=5)\n",
        "    features = []\n",
        "    for c in coeffs:\n",
        "        features.append(np.mean(c))\n",
        "        features.append(np.std(c))\n",
        "        features.append(np.min(c))\n",
        "        features.append(np.max(c))\n",
        "    return np.array(features)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD, PROCESS, AND EXTRACT FEATURES FROM DATA\n",
        "# ==============================================================================\n",
        "\n",
        "files = ['S001R04.edf', 'S001R08.edf', 'S001R12.edf']\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "print(\"\\nStarting data processing...\")\n",
        "for file in files:\n",
        "    print(f\"Processing file: {file}\")\n",
        "\n",
        "    raw = mne.io.read_raw_edf(file, preload=True, verbose=False)\n",
        "\n",
        "    events, event_id_map = mne.events_from_annotations(raw, event_id={'T0': 1, 'T1': 2, 'T2': 3}, verbose=False)\n",
        "\n",
        "    epochs_event_id = {'left': 2, 'right': 3}\n",
        "\n",
        "    # ==========================================================================\n",
        "    # FIX: Use the exact channel names with two periods at the end\n",
        "    # ==========================================================================\n",
        "    picks_channels = ['C3..', 'C4..']\n",
        "\n",
        "    epochs = mne.Epochs(raw, events, epochs_event_id, tmin=0.0, tmax=4.0, proj=False,\n",
        "                        picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "\n",
        "    labels = epochs.events[:, -1]\n",
        "    data = epochs.get_data()\n",
        "\n",
        "    for i in range(len(labels)):\n",
        "        filtered_c3 = bandpass_filter(data[i, 0, :])\n",
        "        filtered_c4 = bandpass_filter(data[i, 1, :])\n",
        "\n",
        "        features_c3 = extract_features(filtered_c3)\n",
        "        features_c4 = extract_features(filtered_c4)\n",
        "\n",
        "        combined_features = np.concatenate([features_c3, features_c4])\n",
        "\n",
        "        all_features.append(combined_features)\n",
        "        all_labels.append(labels[i])\n",
        "\n",
        "X = np.array(all_features)\n",
        "y = np.array(all_labels)\n",
        "\n",
        "print(\"\\n✅ Data processing complete!\")\n",
        "print(f\"Shape of feature matrix (X): {X.shape}\")\n",
        "print(f\"Shape of labels vector (y): {y.shape}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN AND TEST THE SVM MODEL\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nStarting model training...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "model = SVC(kernel='rbf', C=10, gamma='scale', probability=True)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "print(\"\\n✅ Model training complete!\")\n",
        "print(\"=\"*30)\n",
        "print(f\"ACCURACY ON TEST DATA: {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "# Install the 'mne' library for reading EEG data files\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "import pywt\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE PROCESSING FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def extract_features(signal):\n",
        "    \"\"\"Extracts features from a signal using Discrete Wavelet Transform (DWT).\"\"\"\n",
        "    coeffs = pywt.wavedec(signal, 'db4', level=5)\n",
        "    features = []\n",
        "    for c in coeffs:\n",
        "        features.append(np.mean(c))\n",
        "        features.append(np.std(c))\n",
        "        features.append(np.min(c))\n",
        "        features.append(np.max(c))\n",
        "    return np.array(features)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD, PROCESS, AND EXTRACT FEATURES FROM DATA\n",
        "# ==============================================================================\n",
        "\n",
        "# Using data from ONLY Subject 2\n",
        "files = [\n",
        "    'S002R04.edf', 'S002R08.edf', 'S002R12.edf'\n",
        "]\n",
        "\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "print(\"\\nStarting data processing...\")\n",
        "for file in files:\n",
        "    try:\n",
        "        print(f\"Processing file: {file}\")\n",
        "        raw = mne.io.read_raw_edf(file, preload=True, verbose=False)\n",
        "        events, event_id_map = mne.events_from_annotations(raw, event_id={'T0': 1, 'T1': 2, 'T2': 3}, verbose=False)\n",
        "        epochs_event_id = {'left': 2, 'right': 3}\n",
        "\n",
        "        picks_channels = ['C3..', 'C4..']\n",
        "\n",
        "        epochs = mne.Epochs(raw, events, epochs_event_id, tmin=0.0, tmax=4.0, proj=False,\n",
        "                            picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "\n",
        "        labels = epochs.events[:, -1]\n",
        "        data = epochs.get_data()\n",
        "\n",
        "        for i in range(len(labels)):\n",
        "            filtered_c3 = bandpass_filter(data[i, 0, :])\n",
        "            filtered_c4 = bandpass_filter(data[i, 1, :])\n",
        "\n",
        "            features_c3 = extract_features(filtered_c3)\n",
        "            features_c4 = extract_features(filtered_c4)\n",
        "\n",
        "            combined_features = np.concatenate([features_c3, features_c4])\n",
        "\n",
        "            all_features.append(combined_features)\n",
        "            all_labels.append(labels[i])\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process {file}. Error: {e}\")\n",
        "\n",
        "\n",
        "X = np.array(all_features)\n",
        "y = np.array(all_labels)\n",
        "\n",
        "print(\"\\n✅ Data processing complete!\")\n",
        "print(f\"Shape of feature matrix (X): {X.shape}\")\n",
        "print(f\"Shape of labels vector (y): {y.shape}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN AND TEST THE SVM MODEL\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nStarting model training...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ==========================================================================\n",
        "# IMPROVEMENT: Tune the model for Subject 2 by using a more flexible kernel\n",
        "# ==========================================================================\n",
        "model = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "print(\"\\n✅ Model training complete!\")\n",
        "print(\"=\"*30)\n",
        "print(f\"ACCURACY ON TEST DATA (Subject 2 Tuned): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4vW3AxMg7_c",
        "outputId": "7822b8ba-cb83-4049-d8e2-25802443733a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Starting data processing...\n",
            "Processing file: S002R04.edf\n",
            "Processing file: S002R08.edf\n",
            "Processing file: S002R12.edf\n",
            "\n",
            "✅ Data processing complete!\n",
            "Shape of feature matrix (X): (45, 48)\n",
            "Shape of labels vector (y): (45,)\n",
            "\n",
            "Starting model training...\n",
            "\n",
            "✅ Model training complete!\n",
            "==============================\n",
            "ACCURACY ON TEST DATA (Subject 2 Tuned): 55.56%\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "import pywt\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE PROCESSING FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def extract_features(signal):\n",
        "    coeffs = pywt.wavedec(signal, 'db4', level=5)\n",
        "    features = []\n",
        "    for c in coeffs:\n",
        "        features.append(np.mean(c))\n",
        "        features.append(np.std(c))\n",
        "        features.append(np.min(c))\n",
        "        features.append(np.max(c))\n",
        "    return np.array(features)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD, PROCESS, AND EXTRACT FEATURES FROM DATA\n",
        "# ==============================================================================\n",
        "\n",
        "# Using data from a single, tuned subject (e.g., Subject 2)\n",
        "files = ['S002R04.edf', 'S002R08.edf', 'S002R12.edf']\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "print(\"\\nStarting data processing...\")\n",
        "for file in files:\n",
        "    try:\n",
        "        print(f\"Processing file: {file}\")\n",
        "        raw = mne.io.read_raw_edf(file, preload=True, verbose=False)\n",
        "        events, event_id_map = mne.events_from_annotations(raw, event_id={'T0': 1, 'T1': 2, 'T2': 3}, verbose=False)\n",
        "        epochs_event_id = {'left': 2, 'right': 3}\n",
        "\n",
        "        # ==========================================================================\n",
        "        # IMPROVEMENT: Use 8 channels over the motor cortex instead of 2\n",
        "        # ==========================================================================\n",
        "        picks_channels = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "        epochs = mne.Epochs(raw, events, epochs_event_id, tmin=0.0, tmax=4.0, proj=False,\n",
        "                            picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "\n",
        "        labels = epochs.events[:, -1]\n",
        "        data = epochs.get_data() # Shape is (n_trials, n_channels, n_times)\n",
        "\n",
        "        # Process each epoch (trial)\n",
        "        for i in range(len(labels)):\n",
        "            trial_features = []\n",
        "            # Loop through each channel for the current trial\n",
        "            for chan_idx in range(data.shape[1]):\n",
        "                channel_data = data[i, chan_idx, :]\n",
        "                filtered_channel = bandpass_filter(channel_data)\n",
        "                channel_features = extract_features(filtered_channel)\n",
        "                trial_features.append(channel_features)\n",
        "\n",
        "            # Combine all channel features into one long vector for this trial\n",
        "            combined_features = np.concatenate(trial_features)\n",
        "\n",
        "            all_features.append(combined_features)\n",
        "            all_labels.append(labels[i])\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process {file}. Error: {e}\")\n",
        "\n",
        "X = np.array(all_features)\n",
        "y = np.array(all_labels)\n",
        "\n",
        "print(\"\\n✅ Data processing complete!\")\n",
        "print(f\"Shape of feature matrix (X): {X.shape}\") # Shape will now be (45, 192)\n",
        "print(f\"Shape of labels vector (y): {y.shape}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN AND TEST THE SVM MODEL\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nStarting model training...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "model = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "print(\"\\n✅ Model training complete!\")\n",
        "print(\"=\"*30)\n",
        "print(f\"ACCURACY ON TEST DATA (8 Channels): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*30)\n",
        "#i used dwt for this,it looks at each channel speperately so i dont want this, i want to look at all channels simultaneously\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD_vLEySin_M",
        "outputId": "29d8faea-e5d3-4a30-8864-c9ea163ab980"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Starting data processing...\n",
            "Processing file: S002R04.edf\n",
            "Processing file: S002R08.edf\n",
            "Processing file: S002R12.edf\n",
            "\n",
            "✅ Data processing complete!\n",
            "Shape of feature matrix (X): (45, 192)\n",
            "Shape of labels vector (y): (45,)\n",
            "\n",
            "Starting model training...\n",
            "\n",
            "✅ Model training complete!\n",
            "==============================\n",
            "ACCURACY ON TEST DATA (8 Channels): 55.56%\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Import the CSP algorithm from MNE\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE PREPROCESSING FUNCTION\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD AND PREPARE EPOCHS\n",
        "# ==============================================================================\n",
        "\n",
        "# Using data from a single, tuned subject (Subject 2)\n",
        "files = ['S002R04.edf', 'S002R08.edf', 'S002R12.edf']\n",
        "\n",
        "all_epochs_data = []\n",
        "all_epochs_labels = []\n",
        "\n",
        "print(\"\\nStarting data processing...\")\n",
        "for file in files:\n",
        "    try:\n",
        "        print(f\"Processing file: {file}\")\n",
        "        raw = mne.io.read_raw_edf(file, preload=True, verbose=False)\n",
        "        events, event_id_map = mne.events_from_annotations(raw, event_id={'T0': 1, 'T1': 2, 'T2': 3}, verbose=False)\n",
        "        epochs_event_id = {'left': 2, 'right': 3}\n",
        "\n",
        "        # We will use the same 8 channels as before\n",
        "        picks_channels = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "        epochs = mne.Epochs(raw, events, epochs_event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                            picks=picks_channels, baseline=(0.5, 0.5), preload=True, verbose=False)\n",
        "\n",
        "        # Apply the bandpass filter to the epoched data\n",
        "        epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "        all_epochs_data.append(epochs.get_data())\n",
        "        all_epochs_labels.append(epochs.events[:, -1])\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process {file}. Error: {e}\")\n",
        "\n",
        "# Combine data from all files\n",
        "X = np.concatenate(all_epochs_data)\n",
        "y = np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"\\n✅ Data processing complete!\")\n",
        "print(f\"Shape of data matrix (X): {X.shape}\") # Shape is (n_trials, n_channels, n_times)\n",
        "print(f\"Shape of labels vector (y): {y.shape}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN AND TEST THE CSP + SVM PIPELINE\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nStarting model training with CSP...\")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create the CSP object. n_components is the number of virtual channels to create.\n",
        "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
        "\n",
        "# Create the SVM classifier\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "\n",
        "# Create the full pipeline\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "\n",
        "# Train the pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Test the pipeline's accuracy\n",
        "accuracy = pipeline.score(X_test, y_test)\n",
        "\n",
        "print(\"\\n✅ Model training complete!\")\n",
        "print(\"=\"*30)\n",
        "print(f\"ACCURACY ON TEST DATA (CSP + SVM): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*30)\n",
        "#This is where i used common spatial patterns instead of dwt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlQN36UPjk6-",
        "outputId": "e3ccae1f-7a64-485f-e6e5-432a6dd28ecb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Starting data processing...\n",
            "Processing file: S002R04.edf\n",
            "Processing file: S002R08.edf\n",
            "Processing file: S002R12.edf\n",
            "\n",
            "✅ Data processing complete!\n",
            "Shape of data matrix (X): (45, 8, 561)\n",
            "Shape of labels vector (y): (45,)\n",
            "\n",
            "Starting model training with CSP...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 7.4e-06 (2.2e-16 eps * 8 dim * 4.1e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=2 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=3 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ Model training complete!\n",
            "==============================\n",
            "ACCURACY ON TEST DATA (CSP + SVM): 66.67%\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "import pywt\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Import the CSP algorithm from MNE\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE PREPROCESSING FUNCTION\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD AND PREPARE EPOCHS\n",
        "# ==============================================================================\n",
        "\n",
        "# Using data from a single, tuned subject (Subject 2)\n",
        "files = ['S002R04.edf', 'S002R08.edf', 'S002R12.edf']\n",
        "\n",
        "all_epochs_data = []\n",
        "all_epochs_labels = []\n",
        "\n",
        "print(\"\\nStarting data processing...\")\n",
        "for file in files:\n",
        "    try:\n",
        "        print(f\"Processing file: {file}\")\n",
        "        raw = mne.io.read_raw_edf(file, preload=True, verbose=False)\n",
        "        events, event_id_map = mne.events_from_annotations(raw, event_id={'T0': 1, 'T1': 2, 'T2': 3}, verbose=False)\n",
        "        epochs_event_id = {'left': 2, 'right': 3}\n",
        "\n",
        "        picks_channels = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "        epochs = mne.Epochs(raw, events, epochs_event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                            picks=picks_channels, baseline=(0.5, 0.5), preload=True, verbose=False)\n",
        "\n",
        "        epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "        all_epochs_data.append(epochs.get_data())\n",
        "        all_epochs_labels.append(epochs.events[:, -1])\n",
        "    except Exception as e:\n",
        "        print(f\"Could not process {file}. Error: {e}\")\n",
        "\n",
        "X = np.concatenate(all_epochs_data)\n",
        "y = np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"\\n✅ Data processing complete!\")\n",
        "print(f\"Shape of data matrix (X): {X.shape}\")\n",
        "print(f\"Shape of labels vector (y): {y.shape}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: AUTOMATE MODEL TUNING WITH GRIDSEARCHCV\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nStarting automated model tuning with GridSearchCV...\")\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create the pipeline with CSP and SVM\n",
        "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "\n",
        "# Define the grid of parameters to search\n",
        "param_grid = {\n",
        "    'CSP__n_components': [2, 4, 6],\n",
        "    'SVM__kernel': ['linear', 'rbf'],\n",
        "    'SVM__C': [0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Create and run the GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n✅ Automated tuning complete!\")\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "# Test the best found model on the held-out test set\n",
        "best_model = grid_search.best_estimator_\n",
        "accuracy = best_model.score(X_test, y_test)\n",
        "\n",
        "print(\"\\n✅ Final model evaluation complete!\")\n",
        "print(\"=\"*40)\n",
        "print(f\"ACCURACY ON TEST DATA (GridSearchCV Tuned): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QaQUiI-kwRW",
        "outputId": "cd224257-615c-4d70-8157-b179e15a58ae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Starting data processing...\n",
            "Processing file: S002R04.edf\n",
            "Processing file: S002R08.edf\n",
            "Processing file: S002R12.edf\n",
            "\n",
            "✅ Data processing complete!\n",
            "Shape of data matrix (X): (45, 8, 561)\n",
            "Shape of labels vector (y): (45,)\n",
            "\n",
            "Starting automated model tuning with GridSearchCV...\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 7.4e-06 (2.2e-16 eps * 8 dim * 4.1e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=2 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=3 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ Automated tuning complete!\n",
            "Best parameters found: {'CSP__n_components': 6, 'SVM__C': 10, 'SVM__kernel': 'rbf'}\n",
            "\n",
            "✅ Final model evaluation complete!\n",
            "========================================\n",
            "ACCURACY ON TEST DATA (GridSearchCV Tuned): 66.67%\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD AND COMBINE DATA FOR ALL FOUR COMMANDS\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting data processing for 4 commands...\")\n",
        "\n",
        "SUBJECT_ID = 2\n",
        "PICKS_CHANNELS = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "# Task 2: Imagine left/right fist (for 'left' and 'right' commands)\n",
        "task2_runs = [4, 8, 12]\n",
        "X_left, y_left = get_epochs_for_task(SUBJECT_ID, task2_runs, {'T1': 2}, PICKS_CHANNELS)\n",
        "X_right, y_right = get_epochs_for_task(SUBJECT_ID, task2_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "\n",
        "# Task 4: Imagine both feet (for 'forward' command)\n",
        "task4_runs = [6, 10, 14]\n",
        "X_forward, y_forward = get_epochs_for_task(SUBJECT_ID, task4_runs, {'T2': 3}, PICKS_CHANNELS) # T2 in task 4 is 'both feet'\n",
        "y_forward[:] = 4 # Relabel this class to '4' for forward\n",
        "\n",
        "# All Tasks: Rest state (for 'stop' command)\n",
        "all_task_runs = task2_runs + task4_runs\n",
        "X_stop, y_stop = get_epochs_for_task(SUBJECT_ID, all_task_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "y_stop[:] = 1 # Keep label '1' for stop\n",
        "\n",
        "# Combine all data into final X and y arrays\n",
        "X = np.concatenate([X_left, X_right, X_forward, X_stop])\n",
        "y = np.concatenate([y_left, y_right, y_forward, y_stop])\n",
        "\n",
        "print(\"\\n✅ Data processing complete!\")\n",
        "print(f\"Total samples: {len(y)}\")\n",
        "print(f\"Class labels found: {np.unique(y)}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN AND TUNE THE FOUR-CLASS MODEL\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting automated model tuning for 4-class problem...\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create the base pipeline (CSP + SVM)\n",
        "csp = CSP(n_components=8, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "\n",
        "# Use OneVsRestClassifier to handle the multi-class problem\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# Define the grid of parameters to search\n",
        "# Note the syntax: 'estimator__' + 'pipeline_step__' + 'parameter'\n",
        "param_grid = {\n",
        "    'estimator__SVM__kernel': ['rbf'],\n",
        "    'estimator__SVM__C': [1, 10, 100],\n",
        "    'estimator__CSP__n_components': [6, 8]\n",
        "}\n",
        "\n",
        "# Create and run the GridSearchCV\n",
        "grid_search = GridSearchCV(ovr_classifier, param_grid, cv=3, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n✅ Automated tuning complete!\")\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "accuracy = best_model.score(X_test, y_test)\n",
        "\n",
        "print(\"\\n✅ Final model evaluation complete!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (4-CLASS MODEL): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRa0kLNysEK0",
        "outputId": "34becc98-972b-4be8-a841-a48b4456ba67"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Starting data processing for 4 commands...\n",
            "\n",
            "✅ Data processing complete!\n",
            "Total samples: 156\n",
            "Class labels found: [1 2 3 4]\n",
            "\n",
            "Starting automated model tuning for 4-class problem...\n",
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.4e-05 (2.2e-16 eps * 8 dim * 7.9e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.4e-05 (2.2e-16 eps * 8 dim * 7.9e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.4e-05 (2.2e-16 eps * 8 dim * 7.9e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.4e-05 (2.2e-16 eps * 8 dim * 7.9e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ Automated tuning complete!\n",
            "Best parameters found: {'estimator__CSP__n_components': 8, 'estimator__SVM__C': 10, 'estimator__SVM__kernel': 'rbf'}\n",
            "\n",
            "✅ Final model evaluation complete!\n",
            "==================================================\n",
            "FINAL ACCURACY ON TEST DATA (4-CLASS MODEL): 46.88%\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD PRE-TRAINING AND FINE-TUNING DATASETS\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for Transfer Learning...\")\n",
        "\n",
        "SUBJECT_ID = 2\n",
        "PICKS_CHANNELS = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL PHYSICAL MOVEMENT ---\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_ff, y_actual_ff = get_epochs_for_task(SUBJECT_ID, actual_fists_feet_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS) # T1=both fists, T2=both feet\n",
        "\n",
        "# Combine all actual movement data for pre-training\n",
        "X_pretrain = np.concatenate([X_actual_lr, X_actual_ff])\n",
        "y_pretrain = np.concatenate([y_actual_lr, y_actual_ff])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training.\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT (TARGET USER) ---\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "X_finetune, y_finetune = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning.\")\n",
        "\n",
        "# Split the fine-tuning data for final testing\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE MODEL USING TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting Transfer Learning process...\")\n",
        "\n",
        "# Define the model pipeline\n",
        "csp = CSP(n_components=6, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING ---\n",
        "print(\"Phase 1: Pre-training model on ACTUAL movement data...\")\n",
        "pipeline.fit(X_pretrain, y_pretrain)\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(\"Phase 2: Fine-tuning model on IMAGINED movement data...\")\n",
        "pipeline.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = pipeline.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ Transfer Learning complete!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (Transfer Learning): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wLKe4ytyJIW",
        "outputId": "88380818-58d3-4a9a-cb34-a4c6e9591dd2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for Transfer Learning...\n",
            "Loaded 90 samples for pre-training.\n",
            "Loaded 45 samples for fine-tuning.\n",
            "\n",
            "Starting Transfer Learning process...\n",
            "Phase 1: Pre-training model on ACTUAL movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.1e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=2 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=3 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 6.8e-06 (2.2e-16 eps * 8 dim * 3.8e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=2 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=3 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ Transfer Learning complete!\n",
            "==================================================\n",
            "FINAL ACCURACY ON TEST DATA (Transfer Learning): 78.57%\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD DATA FOR TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for 4-Command Transfer Learning...\")\n",
        "\n",
        "SUBJECT_ID = 2\n",
        "PICKS_CHANNELS = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL PHYSICAL MOVEMENT (FOR PRE-TRAINING) ---\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_ff, y_actual_ff = get_epochs_for_task(SUBJECT_ID, actual_fists_feet_runs, {'T2': 4}, PICKS_CHANNELS) # T2 in task 3 is 'both feet' -> forward\n",
        "\n",
        "X_pretrain = np.concatenate([X_actual_lr, X_actual_ff])\n",
        "y_pretrain = np.concatenate([y_actual_lr, y_actual_ff])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training (actual movements).\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT (FOR FINE-TUNING AND TESTING) ---\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14]\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(SUBJECT_ID, imagined_fists_feet_runs, {'T2': 4}, PICKS_CHANNELS)\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "X_finetune = np.concatenate([X_img_lr, X_img_fwd, X_img_stop])\n",
        "y_finetune = np.concatenate([y_img_lr, y_img_fwd, y_img_stop])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning (imagined movements).\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE 4-COMMAND MODEL USING TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting 4-Command Transfer Learning process...\")\n",
        "\n",
        "# Define the base pipeline and wrap it in a OneVsRestClassifier\n",
        "csp = CSP(n_components=8, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING ---\n",
        "print(\"Phase 1: Pre-training model on ACTUAL movement data...\")\n",
        "ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(\"Phase 2: Fine-tuning model on IMAGINED movement data...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ 4-Command Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (4-Command Transfer Learning): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "xHtenTvPz-Yz",
        "outputId": "34cd7dac-cd3c-4284-c197-d931c3f70236"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for 4-Command Transfer Learning...\n",
            "Could not process S002R05.edf. Error: No matching events found for T2 (event id 4)\n",
            "Could not process S002R09.edf. Error: No matching events found for T2 (event id 4)\n",
            "Could not process S002R13.edf. Error: No matching events found for T2 (event id 4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 1 dimension(s)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3998498794.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mX_actual_ff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_actual_ff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_epochs_for_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUBJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_fists_feet_runs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'T2'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPICKS_CHANNELS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# T2 in task 3 is 'both feet' -> forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mX_pretrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_actual_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_actual_ff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0my_pretrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_actual_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_actual_ff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded {len(y_pretrain)} samples for pre-training (actual movements).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 1 dimension(s)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD DATA FOR TRANSFER LEARNING (ROBUST VERSION)\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for 4-Command Transfer Learning...\")\n",
        "\n",
        "SUBJECT_ID = 2\n",
        "PICKS_CHANNELS = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL PHYSICAL MOVEMENT (FOR PRE-TRAINING) ---\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_ff, y_actual_ff = get_epochs_for_task(SUBJECT_ID, actual_fists_feet_runs, {'T2': 4}, PICKS_CHANNELS)\n",
        "\n",
        "# --- FIX: Build lists of non-empty arrays to concatenate ---\n",
        "pretrain_data_list = []\n",
        "pretrain_labels_list = []\n",
        "if X_actual_lr.size > 0:\n",
        "    pretrain_data_list.append(X_actual_lr)\n",
        "    pretrain_labels_list.append(y_actual_lr)\n",
        "if X_actual_ff.size > 0:\n",
        "    pretrain_data_list.append(X_actual_ff)\n",
        "    pretrain_labels_list.append(y_actual_ff)\n",
        "\n",
        "X_pretrain = np.concatenate(pretrain_data_list) if pretrain_data_list else np.array([])\n",
        "y_pretrain = np.concatenate(pretrain_labels_list) if pretrain_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training (actual movements).\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT (FOR FINE-TUNING AND TESTING) ---\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14]\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(SUBJECT_ID, imagined_fists_feet_runs, {'T2': 4}, PICKS_CHANNELS)\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "X_finetune = np.concatenate([X_img_lr, X_img_fwd, X_img_stop])\n",
        "y_finetune = np.concatenate([y_img_lr, y_img_fwd, y_img_stop])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning (imagined movements).\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE 4-COMMAND MODEL USING TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting 4-Command Transfer Learning process...\")\n",
        "\n",
        "csp = CSP(n_components=8, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING (only if data is available) ---\n",
        "if X_pretrain.size > 0:\n",
        "    print(\"Phase 1: Pre-training model on ACTUAL movement data...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(\"Phase 2: Training/Fine-tuning model on IMAGINED movement data...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ 4-Command Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (4-Command Transfer Learning): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "tpgnFAn01RV1",
        "outputId": "575e51d3-21ba-4087-de79-c9b167ae12c4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for 4-Command Transfer Learning...\n",
            "Could not process S002R05.edf. Error: No matching events found for T2 (event id 4)\n",
            "Could not process S002R09.edf. Error: No matching events found for T2 (event id 4)\n",
            "Could not process S002R13.edf. Error: No matching events found for T2 (event id 4)\n",
            "Loaded 45 samples for pre-training (actual movements).\n",
            "Could not process S002R06.edf. Error: No matching events found for T2 (event id 4)\n",
            "Could not process S002R10.edf. Error: No matching events found for T2 (event id 4)\n",
            "Could not process S002R14.edf. Error: No matching events found for T2 (event id 4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 1 dimension(s)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3508674937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mX_img_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_img_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_epochs_for_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUBJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_imagined_runs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'T0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPICKS_CHANNELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mX_finetune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_img_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_img_fwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_img_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0my_finetune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_img_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_img_fwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_img_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded {len(y_finetune)} samples for fine-tuning (imagined movements).\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 3 dimension(s) and the array at index 1 has 1 dimension(s)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with just left right nd stop  # ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD DATA FOR A THREE-COMMAND MODEL\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for 3-Command Transfer Learning...\")\n",
        "\n",
        "SUBJECT_ID = 2\n",
        "PICKS_CHANNELS = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL LEFT/RIGHT MOVEMENT (FOR PRE-TRAINING) ---\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "X_pretrain, y_pretrain = get_epochs_for_task(SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training (actual left/right).\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED LEFT/RIGHT/STOP (FOR FINE-TUNING) ---\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "X_finetune = np.concatenate([X_img_lr, X_img_stop])\n",
        "y_finetune = np.concatenate([y_img_lr, y_img_stop])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning (imagined left, right, stop).\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE 3-COMMAND MODEL USING TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting 3-Command Transfer Learning process...\")\n",
        "\n",
        "csp = CSP(n_components=8, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING (only if data is available) ---\n",
        "if X_pretrain.size > 0:\n",
        "    print(\"Phase 1: Pre-training model on ACTUAL movement data...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(\"Phase 2: Fine-tuning model on IMAGINED movement data...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ 3-Command Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (3-Command Transfer Learning): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PodQRQo2PDV",
        "outputId": "0e4552bd-41a5-4c1f-c5f0-df8003652e74"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for 3-Command Transfer Learning...\n",
            "Loaded 45 samples for pre-training (actual left/right).\n",
            "Loaded 90 samples for fine-tuning (imagined left, right, stop).\n",
            "\n",
            "Starting 3-Command Transfer Learning process...\n",
            "Phase 1: Pre-training model on ACTUAL movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 8.6e-06 (2.2e-16 eps * 8 dim * 4.8e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1e-05 (2.2e-16 eps * 8 dim * 5.6e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1e-05 (2.2e-16 eps * 8 dim * 5.6e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1e-05 (2.2e-16 eps * 8 dim * 5.6e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ 3-Command Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (3-Command Transfer Learning): 48.15%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD DATA FOR A THREE-COMMAND MODEL\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for 3-Command Transfer Learning (4-Channel)...\")\n",
        "\n",
        "SUBJECT_ID = 2\n",
        "# --- MODIFICATION: Use only the 4 most critical channels ---\n",
        "PICKS_CHANNELS = ['C3..', 'Cz..', 'C4..', 'Cpz.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL LEFT/RIGHT MOVEMENT (FOR PRE-TRAINING) ---\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "X_pretrain, y_pretrain = get_epochs_for_task(SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training (actual left/right).\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED LEFT/RIGHT/STOP (FOR FINE-TUNING) ---\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "X_finetune = np.concatenate([X_img_lr, X_img_stop])\n",
        "y_finetune = np.concatenate([y_img_lr, y_img_stop])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning (imagined left, right, stop).\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE 3-COMMAND MODEL USING TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting 3-Command Transfer Learning process (4-Channel)...\")\n",
        "\n",
        "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False) # n_components cannot be larger than n_channels\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING (only if data is available) ---\n",
        "if X_pretrain.size > 0:\n",
        "    print(\"Phase 1: Pre-training model on ACTUAL movement data...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(\"Phase 2: Fine-tuning model on IMAGINED movement data...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ 3-Command Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (4-Channel, 3-Command Model): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWq92Cr72rvR",
        "outputId": "dc035ea6-61de-4310-c1b0-2a9d98e8f4c8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for 3-Command Transfer Learning (4-Channel)...\n",
            "Loaded 45 samples for pre-training (actual left/right).\n",
            "Loaded 90 samples for fine-tuning (imagined left, right, stop).\n",
            "\n",
            "Starting 3-Command Transfer Learning process (4-Channel)...\n",
            "Phase 1: Pre-training model on ACTUAL movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.1e-06 (2.2e-16 eps * 4 dim * 3.5e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.7e-06 (2.2e-16 eps * 4 dim * 4.2e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.7e-06 (2.2e-16 eps * 4 dim * 4.2e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.7e-06 (2.2e-16 eps * 4 dim * 4.2e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ 3-Command Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (4-Channel, 3-Command Model): 51.85%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD DATA FOR TRANSFER LEARNING (SUBJECT 5)\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for 4-Command Transfer Learning...\")\n",
        "\n",
        "# --- MODIFICATION: Set the Subject ID to 5 ---\n",
        "SUBJECT_ID = 5\n",
        "PICKS_CHANNELS = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL PHYSICAL MOVEMENT (FOR PRE-TRAINING) ---\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_ff, y_actual_ff = get_epochs_for_task(SUBJECT_ID, actual_fists_feet_runs, {'T2': 4}, PICKS_CHANNELS) # T2 in task 3 is 'both feet' -> forward\n",
        "\n",
        "# Build lists of non-empty arrays to concatenate\n",
        "pretrain_data_list = []\n",
        "pretrain_labels_list = []\n",
        "if X_actual_lr.size > 0:\n",
        "    pretrain_data_list.append(X_actual_lr)\n",
        "    pretrain_labels_list.append(y_actual_lr)\n",
        "if X_actual_ff.size > 0:\n",
        "    pretrain_data_list.append(X_actual_ff)\n",
        "    pretrain_labels_list.append(y_actual_ff)\n",
        "\n",
        "X_pretrain = np.concatenate(pretrain_data_list) if pretrain_data_list else np.array([])\n",
        "y_pretrain = np.concatenate(pretrain_labels_list) if pretrain_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training (actual movements).\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT (FOR FINE-TUNING AND TESTING) ---\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14]\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(SUBJECT_ID, imagined_fists_feet_runs, {'T2': 4}, PICKS_CHANNELS)\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "# Build lists of non-empty arrays for fine-tuning data\n",
        "finetune_data_list = []\n",
        "finetune_labels_list = []\n",
        "if X_img_lr.size > 0:\n",
        "    finetune_data_list.append(X_img_lr)\n",
        "    finetune_labels_list.append(y_img_lr)\n",
        "if X_img_fwd.size > 0:\n",
        "    finetune_data_list.append(X_img_fwd)\n",
        "    finetune_labels_list.append(y_img_fwd)\n",
        "if X_img_stop.size > 0:\n",
        "    finetune_data_list.append(X_img_stop)\n",
        "    finetune_labels_list.append(y_img_stop)\n",
        "\n",
        "X_finetune = np.concatenate(finetune_data_list) if finetune_data_list else np.array([])\n",
        "y_finetune = np.concatenate(finetune_labels_list) if finetune_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning (imagined movements).\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE 4-COMMAND MODEL USING TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting 4-Command Transfer Learning process...\")\n",
        "\n",
        "csp = CSP(n_components=8, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING (only if data is available) ---\n",
        "if X_pretrain.size > 0:\n",
        "    print(\"Phase 1: Pre-training model on ACTUAL movement data...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(\"Phase 2: Fine-tuning model on IMAGINED movement data...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ 4-Command Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (4-Command Transfer Learning, Subject 5): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C43SW1U59Nq9",
        "outputId": "679b2151-0a04-44ed-d298-d15b46ff98c0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for 4-Command Transfer Learning...\n",
            "Could not process S005R05.edf. Error: No matching events found for T2 (event id 4)\n",
            "Could not process S005R09.edf. Error: No matching events found for T2 (event id 4)\n",
            "Could not process S005R13.edf. Error: No matching events found for T2 (event id 4)\n",
            "Loaded 45 samples for pre-training (actual movements).\n",
            "Could not process S005R06.edf. Error: No matching events found for T2 (event id 4)\n",
            "Could not process S005R10.edf. Error: No matching events found for T2 (event id 4)\n",
            "Could not process S005R14.edf. Error: No matching events found for T2 (event id 4)\n",
            "Loaded 135 samples for fine-tuning (imagined movements).\n",
            "\n",
            "Starting 4-Command Transfer Learning process...\n",
            "Phase 1: Pre-training model on ACTUAL movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 5.9e-06 (2.2e-16 eps * 8 dim * 3.3e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 9.2e-06 (2.2e-16 eps * 8 dim * 5.2e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 9.2e-06 (2.2e-16 eps * 8 dim * 5.2e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 9.2e-06 (2.2e-16 eps * 8 dim * 5.2e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ 4-Command Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (4-Command Transfer Learning, Subject 5): 68.29%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD DATA FOR TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for 4-Command Transfer Learning...\")\n",
        "\n",
        "SUBJECT_ID = 2\n",
        "PICKS_CHANNELS = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL PHYSICAL MOVEMENT (FOR PRE-TRAINING) ---\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_fwd, y_actual_fwd = get_epochs_for_task(SUBJECT_ID, actual_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS) # T2 in task 3 is 'both feet'\n",
        "if y_actual_fwd.size > 0: y_actual_fwd[:] = 4 # Relabel this class to '4' for forward\n",
        "\n",
        "pretrain_data_list = []\n",
        "pretrain_labels_list = []\n",
        "if X_actual_lr.size > 0:\n",
        "    pretrain_data_list.append(X_actual_lr)\n",
        "    pretrain_labels_list.append(y_actual_lr)\n",
        "if X_actual_fwd.size > 0:\n",
        "    pretrain_data_list.append(X_actual_fwd)\n",
        "    pretrain_labels_list.append(y_actual_fwd)\n",
        "\n",
        "X_pretrain = np.concatenate(pretrain_data_list) if pretrain_data_list else np.array([])\n",
        "y_pretrain = np.concatenate(pretrain_labels_list) if pretrain_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training (actual movements).\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT (FOR FINE-TUNING AND TESTING) ---\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14]\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(SUBJECT_ID, imagined_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_img_fwd.size > 0: y_img_fwd[:] = 4 # Relabel this class to '4' for forward\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "X_finetune = np.concatenate([X_img_lr, X_img_fwd, X_img_stop])\n",
        "y_finetune = np.concatenate([y_img_lr, y_img_fwd, y_img_stop])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning (imagined movements).\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE 4-COMMAND MODEL USING TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting 4-Command Transfer Learning process...\")\n",
        "\n",
        "csp = CSP(n_components=8, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING (only if data is available) ---\n",
        "if X_pretrain.size > 0:\n",
        "    print(\"Phase 1: Pre-training model on ACTUAL movement data...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(\"Phase 2: Fine-tuning model on IMAGINED movement data...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ 4-Command Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (4-Command Transfer Learning): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeAd8TX_FicG",
        "outputId": "ba2679a0-a228-42d1-b6dd-3109213d25b5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for 4-Command Transfer Learning...\n",
            "Loaded 69 samples for pre-training (actual movements).\n",
            "Loaded 156 samples for fine-tuning (imagined movements).\n",
            "\n",
            "Starting 4-Command Transfer Learning process...\n",
            "Phase 1: Pre-training model on ACTUAL movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.1e-05 (2.2e-16 eps * 8 dim * 6.3e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.1e-05 (2.2e-16 eps * 8 dim * 6.3e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.1e-05 (2.2e-16 eps * 8 dim * 6.3e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ 4-Command Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (4-Command Transfer Learning): 53.19%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD DATA FOR TRANSFER LEARNING (4-CHANNEL)\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for 4-Command Transfer Learning (4-Channel)...\")\n",
        "\n",
        "SUBJECT_ID = 5 # Using Subject 5 as requested\n",
        "# --- MODIFICATION: Use only the 4 most critical channels ---\n",
        "PICKS_CHANNELS = ['C3..', 'Cz..', 'C4..', 'Cpz.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL PHYSICAL MOVEMENT (FOR PRE-TRAINING) ---\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_fwd, y_actual_fwd = get_epochs_for_task(SUBJECT_ID, actual_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_actual_fwd.size > 0: y_actual_fwd[:] = 4 # Relabel this class to '4' for forward\n",
        "\n",
        "pretrain_data_list = []\n",
        "pretrain_labels_list = []\n",
        "if X_actual_lr.size > 0:\n",
        "    pretrain_data_list.append(X_actual_lr)\n",
        "    pretrain_labels_list.append(y_actual_lr)\n",
        "if X_actual_fwd.size > 0:\n",
        "    pretrain_data_list.append(X_actual_fwd)\n",
        "    pretrain_labels_list.append(y_actual_fwd)\n",
        "\n",
        "X_pretrain = np.concatenate(pretrain_data_list) if pretrain_data_list else np.array([])\n",
        "y_pretrain = np.concatenate(pretrain_labels_list) if pretrain_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training (actual movements).\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT (FOR FINE-TUNING AND TESTING) ---\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14]\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(SUBJECT_ID, imagined_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_img_fwd.size > 0: y_img_fwd[:] = 4 # Relabel this class to '4' for forward\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "finetune_data_list = []\n",
        "finetune_labels_list = []\n",
        "if X_img_lr.size > 0:\n",
        "    finetune_data_list.append(X_img_lr)\n",
        "    finetune_labels_list.append(y_img_lr)\n",
        "if X_img_fwd.size > 0:\n",
        "    finetune_data_list.append(X_img_fwd)\n",
        "    finetune_labels_list.append(y_img_fwd)\n",
        "if X_img_stop.size > 0:\n",
        "    finetune_data_list.append(X_img_stop)\n",
        "    finetune_labels_list.append(y_img_stop)\n",
        "\n",
        "X_finetune = np.concatenate(finetune_data_list) if finetune_data_list else np.array([])\n",
        "y_finetune = np.concatenate(finetune_labels_list) if finetune_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning (imagined movements).\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE 4-COMMAND MODEL (4-CHANNEL) USING TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting 4-Command Transfer Learning process (4-Channel)...\")\n",
        "\n",
        "# --- MODIFICATION: Adjust CSP components for 4 channels ---\n",
        "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING ---\n",
        "if X_pretrain.size > 0:\n",
        "    print(\"Phase 1: Pre-training model on ACTUAL movement data...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(\"Phase 2: Fine-tuning model on IMAGINED movement data...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ 4-Command Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (4-Channel, 4-Command Model, Subject 5): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZr9S7xpGkpw",
        "outputId": "270dc01b-632a-4f05-8303-f268e21c3864"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for 4-Command Transfer Learning (4-Channel)...\n",
            "Loaded 68 samples for pre-training (actual movements).\n",
            "Loaded 157 samples for fine-tuning (imagined movements).\n",
            "\n",
            "Starting 4-Command Transfer Learning process (4-Channel)...\n",
            "Phase 1: Pre-training model on ACTUAL movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.6e-06 (2.2e-16 eps * 4 dim * 2.9e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.6e-06 (2.2e-16 eps * 4 dim * 2.9e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.6e-06 (2.2e-16 eps * 4 dim * 2.9e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ 4-Command Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (4-Channel, 4-Command Model, Subject 5): 60.42%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD DATA FOR TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for Transfer Learning...\")\n",
        "\n",
        "SUBJECT_ID = 2 # Change this to the subject you want to test\n",
        "PICKS_CHANNELS = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL PHYSICAL MOVEMENT (FOR PRE-TRAINING) ---\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_fwd, y_actual_fwd = get_epochs_for_task(SUBJECT_ID, actual_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_actual_fwd.size > 0: y_actual_fwd[:] = 4 # Relabel this class to '4' for forward\n",
        "\n",
        "pretrain_data_list = []\n",
        "pretrain_labels_list = []\n",
        "if X_actual_lr.size > 0:\n",
        "    pretrain_data_list.append(X_actual_lr)\n",
        "    pretrain_labels_list.append(y_actual_lr)\n",
        "if X_actual_fwd.size > 0:\n",
        "    pretrain_data_list.append(X_actual_fwd)\n",
        "    pretrain_labels_list.append(y_actual_fwd)\n",
        "\n",
        "X_pretrain = np.concatenate(pretrain_data_list) if pretrain_data_list else np.array([])\n",
        "y_pretrain = np.concatenate(pretrain_labels_list) if pretrain_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training (actual movements).\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT (FOR FINE-TUNING AND TESTING) ---\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14] # ADDING THESE RUNS AS REQUESTED\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(SUBJECT_ID, imagined_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_img_fwd.size > 0: y_img_fwd[:] = 4 # Relabel this class to '4' for forward\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "finetune_data_list = []\n",
        "finetune_labels_list = []\n",
        "if X_img_lr.size > 0:\n",
        "    finetune_data_list.append(X_img_lr)\n",
        "    finetune_labels_list.append(y_img_lr)\n",
        "if X_img_fwd.size > 0:\n",
        "    finetune_data_list.append(X_img_fwd)\n",
        "    finetune_labels_list.append(y_img_fwd)\n",
        "if X_img_stop.size > 0:\n",
        "    finetune_data_list.append(X_img_stop)\n",
        "    finetune_labels_list.append(y_img_stop)\n",
        "\n",
        "X_finetune = np.concatenate(finetune_data_list) if finetune_data_list else np.array([])\n",
        "y_finetune = np.concatenate(finetune_labels_list) if finetune_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning (imagined movements).\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE MODEL USING TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting Transfer Learning process...\")\n",
        "\n",
        "csp = CSP(n_components=8, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING (only if data is available) ---\n",
        "if X_pretrain.size > 0 and len(np.unique(y_pretrain)) > 1:\n",
        "    print(\"Phase 1: Pre-training model on ACTUAL movement data...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing or single-class data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(\"Phase 2: Fine-tuning model on IMAGINED movement data...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (Transfer Learning, Subject {SUBJECT_ID}): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-U8s7-gJETw",
        "outputId": "377dfc5c-3ee9-45fc-a0d3-e8eea4f61dc5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for Transfer Learning...\n",
            "Loaded 69 samples for pre-training (actual movements).\n",
            "Loaded 156 samples for fine-tuning (imagined movements).\n",
            "\n",
            "Starting Transfer Learning process...\n",
            "Phase 1: Pre-training model on ACTUAL movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.1e-05 (2.2e-16 eps * 8 dim * 6.3e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.1e-05 (2.2e-16 eps * 8 dim * 6.3e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.1e-05 (2.2e-16 eps * 8 dim * 6.3e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (Transfer Learning, Subject 2): 53.19%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD INTER-SUBJECT DATA FOR 4 COMMANDS\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for 4-Command Inter-Subject Transfer Learning...\")\n",
        "\n",
        "PRETRAIN_SUBJECT_ID = 5\n",
        "TARGET_SUBJECT_ID = 2\n",
        "PICKS_CHANNELS = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL MOVEMENT FROM PRE-TRAIN SUBJECT (S5) ---\n",
        "print(f\"Loading pre-training data from Subject {PRETRAIN_SUBJECT_ID}...\")\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(PRETRAIN_SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_fwd, y_actual_fwd = get_epochs_for_task(PRETRAIN_SUBJECT_ID, actual_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_actual_fwd.size > 0: y_actual_fwd[:] = 4 # Relabel\n",
        "X_pretrain = np.concatenate([X_actual_lr, X_actual_fwd])\n",
        "y_pretrain = np.concatenate([y_actual_lr, y_actual_fwd])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training.\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT FROM TARGET SUBJECT (S2) ---\n",
        "print(f\"Loading fine-tuning data from Subject {TARGET_SUBJECT_ID}...\")\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14] # Including runs for 'forward'\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(TARGET_SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(TARGET_SUBJECT_ID, imagined_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_img_fwd.size > 0: y_img_fwd[:] = 4 # Relabel\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(TARGET_SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "X_finetune = np.concatenate([X_img_lr, X_img_fwd, X_img_stop])\n",
        "y_finetune = np.concatenate([y_img_lr, y_img_fwd, y_img_stop])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning.\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE 4-COMMAND MODEL USING INTER-SUBJECT TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting Inter-Subject Transfer Learning process...\")\n",
        "\n",
        "csp = CSP(n_components=8, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING ---\n",
        "if X_pretrain.size > 0:\n",
        "    print(f\"Phase 1: Pre-training model on ACTUAL movement data from Subject {PRETRAIN_SUBJECT_ID}...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing pre-train data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(f\"Phase 2: Fine-tuning model on IMAGINED movement data from Subject {TARGET_SUBJECT_ID}...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ Inter-Subject Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (S{PRETRAIN_SUBJECT_ID} -> S{TARGET_SUBJECT_ID}): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8BGPo2VJ8II",
        "outputId": "ce4e13cc-021b-4a7a-dff5-e0c319bd089f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for 4-Command Inter-Subject Transfer Learning...\n",
            "Loading pre-training data from Subject 5...\n",
            "Loaded 68 samples for pre-training.\n",
            "Loading fine-tuning data from Subject 2...\n",
            "Loaded 156 samples for fine-tuning.\n",
            "\n",
            "Starting Inter-Subject Transfer Learning process...\n",
            "Phase 1: Pre-training model on ACTUAL movement data from Subject 5...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 7.2e-06 (2.2e-16 eps * 8 dim * 4.1e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 7.2e-06 (2.2e-16 eps * 8 dim * 4.1e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 7.2e-06 (2.2e-16 eps * 8 dim * 4.1e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data from Subject 2...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.3e-05 (2.2e-16 eps * 8 dim * 7.4e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ Inter-Subject Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (S5 -> S2): 53.19%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD INTER-SUBJECT DATA FOR 4 COMMANDS (4-CHANNEL)\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for 4-Command Inter-Subject Transfer Learning...\")\n",
        "\n",
        "PRETRAIN_SUBJECT_ID = 5\n",
        "TARGET_SUBJECT_ID = 2\n",
        "# --- MODIFICATION: Use only the 4 most critical channels ---\n",
        "PICKS_CHANNELS = ['C3..', 'Cz..', 'C4..', 'Cpz.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL MOVEMENT FROM PRE-TRAIN SUBJECT (S5) ---\n",
        "print(f\"Loading pre-training data from Subject {PRETRAIN_SUBJECT_ID}...\")\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(PRETRAIN_SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_fwd, y_actual_fwd = get_epochs_for_task(PRETRAIN_SUBJECT_ID, actual_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_actual_fwd.size > 0: y_actual_fwd[:] = 4 # Relabel\n",
        "X_pretrain = np.concatenate([X_actual_lr, X_actual_fwd])\n",
        "y_pretrain = np.concatenate([y_actual_lr, y_actual_fwd])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training.\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT FROM TARGET SUBJECT (S2) ---\n",
        "print(f\"Loading fine-tuning data from Subject {TARGET_SUBJECT_ID}...\")\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14]\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(TARGET_SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(TARGET_SUBJECT_ID, imagined_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_img_fwd.size > 0: y_img_fwd[:] = 4 # Relabel\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(TARGET_SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "X_finetune = np.concatenate([X_img_lr, X_img_fwd, X_img_stop])\n",
        "y_finetune = np.concatenate([y_img_lr, y_img_fwd, y_img_stop])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning.\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE 4-COMMAND MODEL USING INTER-SUBJECT TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting Inter-Subject Transfer Learning process...\")\n",
        "\n",
        "# --- MODIFICATION: Adjust CSP components for 4 channels ---\n",
        "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING ---\n",
        "if X_pretrain.size > 0:\n",
        "    print(f\"Phase 1: Pre-training model on ACTUAL movement data from Subject {PRETRAIN_SUBJECT_ID}...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing pre-train data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(f\"Phase 2: Fine-tuning model on IMAGINED movement data from Subject {TARGET_SUBJECT_ID}...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ Inter-Subject Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (4-Channel, S{PRETRAIN_SUBJECT_ID} -> S{TARGET_SUBJECT_ID}): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2MxCk0lK7Fp",
        "outputId": "fb94db44-a125-4209-80c7-b9533c1c8dd1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for 4-Command Inter-Subject Transfer Learning...\n",
            "Loading pre-training data from Subject 5...\n",
            "Loaded 68 samples for pre-training.\n",
            "Loading fine-tuning data from Subject 2...\n",
            "Loaded 156 samples for fine-tuning.\n",
            "\n",
            "Starting Inter-Subject Transfer Learning process...\n",
            "Phase 1: Pre-training model on ACTUAL movement data from Subject 5...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.6e-06 (2.2e-16 eps * 4 dim * 2.9e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.6e-06 (2.2e-16 eps * 4 dim * 2.9e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.6e-06 (2.2e-16 eps * 4 dim * 2.9e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data from Subject 2...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 4.8e-06 (2.2e-16 eps * 4 dim * 5.5e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 4.8e-06 (2.2e-16 eps * 4 dim * 5.5e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 4.8e-06 (2.2e-16 eps * 4 dim * 5.5e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 4.8e-06 (2.2e-16 eps * 4 dim * 5.5e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ Inter-Subject Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (4-Channel, S5 -> S2): 48.94%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD INTER-SUBJECT DATA\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for Inter-Subject Transfer Learning...\")\n",
        "\n",
        "# --- MODIFICATION: Set Pre-train to S2 and Target to S5 ---\n",
        "PRETRAIN_SUBJECT_ID = 2\n",
        "TARGET_SUBJECT_ID = 5\n",
        "PICKS_CHANNELS = ['C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'Cp3.', 'Cpz.', 'Cp4.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL MOVEMENT FROM PRE-TRAIN SUBJECT (S2) ---\n",
        "print(f\"Loading pre-training data from Subject {PRETRAIN_SUBJECT_ID}...\")\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(PRETRAIN_SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_fwd, y_actual_fwd = get_epochs_for_task(PRETRAIN_SUBJECT_ID, actual_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_actual_fwd.size > 0: y_actual_fwd[:] = 4 # Relabel\n",
        "pretrain_data_list = []\n",
        "pretrain_labels_list = []\n",
        "if X_actual_lr.size > 0:\n",
        "    pretrain_data_list.append(X_actual_lr)\n",
        "    pretrain_labels_list.append(y_actual_lr)\n",
        "if X_actual_fwd.size > 0:\n",
        "    pretrain_data_list.append(X_actual_fwd)\n",
        "    pretrain_labels_list.append(y_actual_fwd)\n",
        "X_pretrain = np.concatenate(pretrain_data_list) if pretrain_data_list else np.array([])\n",
        "y_pretrain = np.concatenate(pretrain_labels_list) if pretrain_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training.\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT FROM TARGET SUBJECT (S5) ---\n",
        "print(f\"Loading fine-tuning data from Subject {TARGET_SUBJECT_ID}...\")\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14]\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(TARGET_SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(TARGET_SUBJECT_ID, imagined_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_img_fwd.size > 0: y_img_fwd[:] = 4 # Relabel\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(TARGET_SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "finetune_data_list = []\n",
        "finetune_labels_list = []\n",
        "if X_img_lr.size > 0:\n",
        "    finetune_data_list.append(X_img_lr)\n",
        "    finetune_labels_list.append(y_img_lr)\n",
        "if X_img_fwd.size > 0:\n",
        "    finetune_data_list.append(X_img_fwd)\n",
        "    finetune_labels_list.append(y_img_fwd)\n",
        "if X_img_stop.size > 0:\n",
        "    finetune_data_list.append(X_img_stop)\n",
        "    finetune_labels_list.append(y_img_stop)\n",
        "X_finetune = np.concatenate(finetune_data_list) if finetune_data_list else np.array([])\n",
        "y_finetune = np.concatenate(finetune_labels_list) if finetune_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning.\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE MODEL USING INTER-SUBJECT TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting Inter-Subject Transfer Learning process...\")\n",
        "\n",
        "csp = CSP(n_components=8, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING ---\n",
        "if X_pretrain.size > 0:\n",
        "    print(f\"Phase 1: Pre-training model on ACTUAL movement data from Subject {PRETRAIN_SUBJECT_ID}...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing pre-train data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(f\"Phase 2: Fine-tuning model on IMAGINED movement data from Subject {TARGET_SUBJECT_ID}...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ Inter-Subject Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (S{PRETRAIN_SUBJECT_ID} -> S{TARGET_SUBJECT_ID}): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtuSrYKFLmXQ",
        "outputId": "229eafeb-7698-4a5c-e428-08ed39e3cfda"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for Inter-Subject Transfer Learning...\n",
            "Loading pre-training data from Subject 2...\n",
            "Loaded 69 samples for pre-training.\n",
            "Loading fine-tuning data from Subject 5...\n",
            "Loaded 157 samples for fine-tuning.\n",
            "\n",
            "Starting Inter-Subject Transfer Learning process...\n",
            "Phase 1: Pre-training model on ACTUAL movement data from Subject 2...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.1e-05 (2.2e-16 eps * 8 dim * 6.3e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.1e-05 (2.2e-16 eps * 8 dim * 6.3e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 1.1e-05 (2.2e-16 eps * 8 dim * 6.3e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data from Subject 5...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 9.8e-06 (2.2e-16 eps * 8 dim * 5.5e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 9.8e-06 (2.2e-16 eps * 8 dim * 5.5e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 9.8e-06 (2.2e-16 eps * 8 dim * 5.5e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 9.8e-06 (2.2e-16 eps * 8 dim * 5.5e+09  max singular value)\n",
            "    Estimated rank (data): 8\n",
            "    data: rank 8 computed from 8 data channels with 0 projectors\n",
            "Reducing data rank from 8 -> 8\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ Inter-Subject Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (S2 -> S5): 54.17%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD INTER-SUBJECT DATA (4-CHANNEL)\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for 4-Command Inter-Subject Transfer Learning (4-Channel)...\")\n",
        "\n",
        "# --- MODIFICATION: Switched Pre-train to S2 and Target to S5 ---\n",
        "PRETRAIN_SUBJECT_ID = 2\n",
        "TARGET_SUBJECT_ID = 5\n",
        "PICKS_CHANNELS = ['C3..', 'Cz..', 'C4..', 'Cpz.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL MOVEMENT FROM PRE-TRAIN SUBJECT (S2) ---\n",
        "print(f\"Loading pre-training data from Subject {PRETRAIN_SUBJECT_ID}...\")\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(PRETRAIN_SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_fwd, y_actual_fwd = get_epochs_for_task(PRETRAIN_SUBJECT_ID, actual_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_actual_fwd.size > 0: y_actual_fwd[:] = 4 # Relabel\n",
        "pretrain_data_list = []\n",
        "pretrain_labels_list = []\n",
        "if X_actual_lr.size > 0:\n",
        "    pretrain_data_list.append(X_actual_lr)\n",
        "    pretrain_labels_list.append(y_actual_lr)\n",
        "if X_actual_fwd.size > 0:\n",
        "    pretrain_data_list.append(X_actual_fwd)\n",
        "    pretrain_labels_list.append(y_actual_fwd)\n",
        "X_pretrain = np.concatenate(pretrain_data_list) if pretrain_data_list else np.array([])\n",
        "y_pretrain = np.concatenate(pretrain_labels_list) if pretrain_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training.\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT FROM TARGET SUBJECT (S5) ---\n",
        "print(f\"Loading fine-tuning data from Subject {TARGET_SUBJECT_ID}...\")\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14]\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(TARGET_SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(TARGET_SUBJECT_ID, imagined_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_img_fwd.size > 0: y_img_fwd[:] = 4 # Relabel\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(TARGET_SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "finetune_data_list = []\n",
        "finetune_labels_list = []\n",
        "if X_img_lr.size > 0:\n",
        "    finetune_data_list.append(X_img_lr)\n",
        "    finetune_labels_list.append(y_img_lr)\n",
        "if X_img_fwd.size > 0:\n",
        "    finetune_data_list.append(X_img_fwd)\n",
        "    finetune_labels_list.append(y_img_fwd)\n",
        "if X_img_stop.size > 0:\n",
        "    finetune_data_list.append(X_img_stop)\n",
        "    finetune_labels_list.append(y_img_stop)\n",
        "X_finetune = np.concatenate(finetune_data_list) if finetune_data_list else np.array([])\n",
        "y_finetune = np.concatenate(finetune_labels_list) if finetune_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning.\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE 4-COMMAND MODEL (4-CHANNEL) USING INTER-SUBJECT TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting Inter-Subject Transfer Learning process (4-Channel)...\")\n",
        "\n",
        "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING ---\n",
        "if X_pretrain.size > 0:\n",
        "    print(f\"Phase 1: Pre-training model on ACTUAL movement data from Subject {PRETRAIN_SUBJECT_ID}...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing pre-train data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(f\"Phase 2: Fine-tuning model on IMAGINED movement data from Subject {TARGET_SUBJECT_ID}...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ Inter-Subject Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (S{PRETRAIN_SUBJECT_ID} -> S{TARGET_SUBJECT_ID}): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EredFQJAMxIs",
        "outputId": "13a170f3-c831-468f-d49d-8b99773283a0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for 4-Command Inter-Subject Transfer Learning (4-Channel)...\n",
            "Loading pre-training data from Subject 2...\n",
            "Loaded 69 samples for pre-training.\n",
            "Loading fine-tuning data from Subject 5...\n",
            "Loaded 157 samples for fine-tuning.\n",
            "\n",
            "Starting Inter-Subject Transfer Learning process (4-Channel)...\n",
            "Phase 1: Pre-training model on ACTUAL movement data from Subject 2...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 4.1e-06 (2.2e-16 eps * 4 dim * 4.6e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 4.1e-06 (2.2e-16 eps * 4 dim * 4.6e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 4.1e-06 (2.2e-16 eps * 4 dim * 4.6e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data from Subject 5...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ Inter-Subject Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (S2 -> S5): 60.42%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: INSTALL AND IMPORT LIBRARIES\n",
        "# ==============================================================================\n",
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from mne.decoding import CSP\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 2: DEFINE HELPER FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def bandpass_filter(data, lowcut=8.0, highcut=30.0, fs=160.0, order=5):\n",
        "    \"\"\"Applies a bandpass filter to the data.\"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    y = filtfilt(b, a, data)\n",
        "    return y\n",
        "\n",
        "def get_epochs_for_task(subject_id, run_numbers, event_id, picks_channels):\n",
        "    \"\"\"Helper function to load and extract epochs for specific runs and events.\"\"\"\n",
        "    all_epochs_data = []\n",
        "    all_epochs_labels = []\n",
        "\n",
        "    for run in run_numbers:\n",
        "        filename = f'S{subject_id:03d}R{run:02d}.edf'\n",
        "        try:\n",
        "            raw = mne.io.read_raw_edf(filename, preload=True, verbose=False)\n",
        "            events, _ = mne.events_from_annotations(raw, verbose=False)\n",
        "\n",
        "            epochs = mne.Epochs(raw, events, event_id, tmin=0.5, tmax=4.0, proj=False,\n",
        "                                picks=picks_channels, baseline=None, preload=True, verbose=False)\n",
        "            epochs.apply_function(bandpass_filter, verbose=False)\n",
        "\n",
        "            all_epochs_data.append(epochs.get_data())\n",
        "            all_epochs_labels.append(epochs.events[:, -1])\n",
        "        except Exception as e:\n",
        "            print(f\"Could not process {filename}. Error: {e}\")\n",
        "\n",
        "    if not all_epochs_data:\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    return np.concatenate(all_epochs_data), np.concatenate(all_epochs_labels)\n",
        "\n",
        "print(\"✅ Helper functions defined.\")\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 3: LOAD DATA FOR TRANSFER LEARNING (4-CHANNEL)\n",
        "# ==============================================================================\n",
        "print(\"\\nLoading datasets for Intra-Subject Transfer Learning (4-Channel)...\")\n",
        "\n",
        "SUBJECT_ID = 5 # Change this to the subject you want to test\n",
        "# --- MODIFICATION: Use only the 4 most critical channels ---\n",
        "PICKS_CHANNELS = ['C3..', 'Cz..', 'C4..', 'Cpz.']\n",
        "\n",
        "# --- PHASE 1 DATA: ACTUAL PHYSICAL MOVEMENT (FOR PRE-TRAINING) ---\n",
        "actual_left_right_runs = [3, 7, 11]\n",
        "actual_fists_feet_runs = [5, 9, 13]\n",
        "\n",
        "X_actual_lr, y_actual_lr = get_epochs_for_task(SUBJECT_ID, actual_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_actual_fwd, y_actual_fwd = get_epochs_for_task(SUBJECT_ID, actual_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_actual_fwd.size > 0: y_actual_fwd[:] = 4 # Relabel this class to '4' for forward\n",
        "\n",
        "pretrain_data_list = []\n",
        "pretrain_labels_list = []\n",
        "if X_actual_lr.size > 0:\n",
        "    pretrain_data_list.append(X_actual_lr)\n",
        "    pretrain_labels_list.append(y_actual_lr)\n",
        "if X_actual_fwd.size > 0:\n",
        "    pretrain_data_list.append(X_actual_fwd)\n",
        "    pretrain_labels_list.append(y_actual_fwd)\n",
        "\n",
        "X_pretrain = np.concatenate(pretrain_data_list) if pretrain_data_list else np.array([])\n",
        "y_pretrain = np.concatenate(pretrain_labels_list) if pretrain_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_pretrain)} samples for pre-training (actual movements).\")\n",
        "\n",
        "# --- PHASE 2 DATA: IMAGINED MOVEMENT (FOR FINE-TUNING AND TESTING) ---\n",
        "imagined_left_right_runs = [4, 8, 12]\n",
        "imagined_fists_feet_runs = [6, 10, 14]\n",
        "all_imagined_runs = imagined_left_right_runs + imagined_fists_feet_runs\n",
        "\n",
        "X_img_lr, y_img_lr = get_epochs_for_task(SUBJECT_ID, imagined_left_right_runs, {'T1': 2, 'T2': 3}, PICKS_CHANNELS)\n",
        "X_img_fwd, y_img_fwd = get_epochs_for_task(SUBJECT_ID, imagined_fists_feet_runs, {'T2': 3}, PICKS_CHANNELS)\n",
        "if y_img_fwd.size > 0: y_img_fwd[:] = 4 # Relabel\n",
        "X_img_stop, y_img_stop = get_epochs_for_task(SUBJECT_ID, all_imagined_runs, {'T0': 1}, PICKS_CHANNELS)\n",
        "\n",
        "finetune_data_list = []\n",
        "finetune_labels_list = []\n",
        "if X_img_lr.size > 0:\n",
        "    finetune_data_list.append(X_img_lr)\n",
        "    finetune_labels_list.append(y_img_lr)\n",
        "if X_img_fwd.size > 0:\n",
        "    finetune_data_list.append(X_img_fwd)\n",
        "    finetune_labels_list.append(y_img_fwd)\n",
        "if X_img_stop.size > 0:\n",
        "    finetune_data_list.append(X_img_stop)\n",
        "    finetune_labels_list.append(y_img_stop)\n",
        "\n",
        "X_finetune = np.concatenate(finetune_data_list) if finetune_data_list else np.array([])\n",
        "y_finetune = np.concatenate(finetune_labels_list) if finetune_labels_list else np.array([])\n",
        "print(f\"Loaded {len(y_finetune)} samples for fine-tuning (imagined movements).\")\n",
        "\n",
        "X_train_ft, X_test_ft, y_train_ft, y_test_ft = train_test_split(X_finetune, y_finetune, test_size=0.3, random_state=42, stratify=y_finetune)\n",
        "\n",
        "# ==============================================================================\n",
        "# STEP 4: TRAIN THE MODEL USING INTRA-SUBJECT TRANSFER LEARNING\n",
        "# ==============================================================================\n",
        "print(\"\\nStarting Intra-Subject Transfer Learning process (4-Channel)...\")\n",
        "\n",
        "# --- MODIFICATION: Adjust CSP components for 4 channels ---\n",
        "csp = CSP(n_components=4, reg=None, log=True, norm_trace=False)\n",
        "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
        "pipeline = Pipeline([('CSP', csp), ('SVM', svm)])\n",
        "ovr_classifier = OneVsRestClassifier(pipeline)\n",
        "\n",
        "# --- PHASE 1: PRE-TRAINING ---\n",
        "if X_pretrain.size > 0 and len(np.unique(y_pretrain)) > 1:\n",
        "    print(\"Phase 1: Pre-training model on ACTUAL movement data...\")\n",
        "    ovr_classifier.fit(X_pretrain, y_pretrain)\n",
        "else:\n",
        "    print(\"Phase 1: Skipping pre-training due to missing or single-class data.\")\n",
        "\n",
        "# --- PHASE 2: FINE-TUNING ---\n",
        "print(\"Phase 2: Fine-tuning model on IMAGINED movement data...\")\n",
        "ovr_classifier.fit(X_train_ft, y_train_ft)\n",
        "\n",
        "# --- FINAL EVALUATION ---\n",
        "accuracy = ovr_classifier.score(X_test_ft, y_test_ft)\n",
        "\n",
        "print(\"\\n✅ Intra-Subject Transfer Learning complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"FINAL ACCURACY ON TEST DATA (4-Channel, Subject {SUBJECT_ID}): {accuracy * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdiu6KrD5w33",
        "outputId": "6e4d6190-065a-4e0f-b709-7bdf59f5aac9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.10.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.7 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.7->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.8.3)\n",
            "Downloading mne-1.10.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.10.1\n",
            "✅ Libraries installed and imported successfully.\n",
            "✅ Helper functions defined.\n",
            "\n",
            "Loading datasets for Intra-Subject Transfer Learning (4-Channel)...\n",
            "Loaded 68 samples for pre-training (actual movements).\n",
            "Loaded 157 samples for fine-tuning (imagined movements).\n",
            "\n",
            "Starting Intra-Subject Transfer Learning process (4-Channel)...\n",
            "Phase 1: Pre-training model on ACTUAL movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.6e-06 (2.2e-16 eps * 4 dim * 2.9e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.6e-06 (2.2e-16 eps * 4 dim * 2.9e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 2.6e-06 (2.2e-16 eps * 4 dim * 2.9e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Phase 2: Fine-tuning model on IMAGINED movement data...\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "Computing rank from data with rank=None\n",
            "    Using tolerance 3.5e-06 (2.2e-16 eps * 4 dim * 4e+09  max singular value)\n",
            "    Estimated rank (data): 4\n",
            "    data: rank 4 computed from 4 data channels with 0 projectors\n",
            "Reducing data rank from 4 -> 4\n",
            "Estimating class=0 covariance using EMPIRICAL\n",
            "Done.\n",
            "Estimating class=1 covariance using EMPIRICAL\n",
            "Done.\n",
            "\n",
            "✅ Intra-Subject Transfer Learning complete!\n",
            "============================================================\n",
            "FINAL ACCURACY ON TEST DATA (4-Channel, Subject 5): 60.42%\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "\n",
        "# Load one of your files to inspect it\n",
        "file_to_inspect = 'S001R04.edf'\n",
        "raw = mne.io.read_raw_edf(file_to_inspect, verbose=False)\n",
        "\n",
        "# Print the list of all channel names\n",
        "print(raw.ch_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0tXlK-JfhyS",
        "outputId": "5d75446d-9062-4e93-ff86-007c6ceb86c1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Fc5.', 'Fc3.', 'Fc1.', 'Fcz.', 'Fc2.', 'Fc4.', 'Fc6.', 'C5..', 'C3..', 'C1..', 'Cz..', 'C2..', 'C4..', 'C6..', 'Cp5.', 'Cp3.', 'Cp1.', 'Cpz.', 'Cp2.', 'Cp4.', 'Cp6.', 'Fp1.', 'Fpz.', 'Fp2.', 'Af7.', 'Af3.', 'Afz.', 'Af4.', 'Af8.', 'F7..', 'F5..', 'F3..', 'F1..', 'Fz..', 'F2..', 'F4..', 'F6..', 'F8..', 'Ft7.', 'Ft8.', 'T7..', 'T8..', 'T9..', 'T10.', 'Tp7.', 'Tp8.', 'P7..', 'P5..', 'P3..', 'P1..', 'Pz..', 'P2..', 'P4..', 'P6..', 'P8..', 'Po7.', 'Po3.', 'Poz.', 'Po4.', 'Po8.', 'O1..', 'Oz..', 'O2..', 'Iz..']\n"
          ]
        }
      ]
    }
  ]
}